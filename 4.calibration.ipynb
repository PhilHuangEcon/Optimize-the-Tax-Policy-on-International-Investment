{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29765eef",
   "metadata": {},
   "source": [
    "### Calibration_Version 2.2.0\n",
    "\n",
    "\n",
    "This file copies 2.1.1 and does some further experiments. This file changes the moments of the calibration process. We calibrate $\\sigma$, $\\mu_{c}$ $k$ and $\\theta$.\n",
    "\n",
    "Also we include one more moment into the calibration process: $\\Delta D$\n",
    "\n",
    "The moment of jump-down we are using is the adjusted version.ï¼ˆWe only include the left end in the 100 bin regression.)\n",
    "\n",
    "Changed the last moment: increase in Beta and stayer_mmt\n",
    "\n",
    "Changed the $\\tau_H$ to be 0.225.\n",
    "\n",
    "Change the weighting matrix: now we minimize using the variance-covariance matrix.\n",
    "\n",
    "Change the data moments: we use the data moments from our bootstrap process (2000 times). Also the regression moments we use here are from the de-fixed-effect data.\n",
    "\n",
    "#### version 2.2+ stems from version 2.1.7, where we have got decent and valid estimation results.\n",
    "We fix bugs in calculating the delta_d here. get_Beta_conditional_expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca558ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from matplotlib import pyplot as plt \n",
    "from copulas.datasets import sample_trivariate_xyz\n",
    "from copulas.visualization import scatter_3d, compare_3d\n",
    "from copulas.multivariate import GaussianMultivariate\n",
    "from copulas.univariate import BetaUnivariate, GaussianKDE, GaussianUnivariate\n",
    "from scipy.stats import pareto, beta\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "from scipy import optimize\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.optimize import minimize, rosen, rosen_der\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae1b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/philhuang/Desktop/FDI/workingdata/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a765966",
   "metadata": {},
   "source": [
    "### P1.  Preparation.\n",
    "#### Load in some functions we need to use for solving for optimal $\\eta$ and $\\delta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e291bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eqaution 8 where we calculate optimal beta.\n",
    "def get_optimal_beta(sigma, eta):\n",
    "    part1     = eta/(1-eta)\n",
    "    part2     = 1-(sigma-1)*(1-eta)/sigma \n",
    "    part3     = 1- (sigma-1)*eta/sigma \n",
    "    temp      = np.sqrt(part1*part2/part3)\n",
    "    beta_star = temp/(1+temp)\n",
    "    return beta_star\n",
    "\n",
    "# From (8), we solve for eta given beta. We need to use binary search.\n",
    "# First, we define a function with which we get the value which is closer to the target.\n",
    "# when we have two candidates RHS_vals[a]<RHS_vals[b], which means the a_th RHS value smaller than the target \n",
    "# and the b_th RHS values bigger than the target.\n",
    "\n",
    "def get_closer_num(lst,a,b,target):\n",
    "    baseline = abs(lst[a]-target)\n",
    "    if abs(lst[b]-target) <= baseline:\n",
    "        return b\n",
    "    else:\n",
    "        return a\n",
    "\n",
    "# Then we define a binary search function to solve the function.\n",
    "# In general, lst_a contains the target we want to search for, and we want to return the corresponding \n",
    "# element in lst_b\n",
    "def get_ans(lst_a, lst_b, target):\n",
    "    \n",
    "    left=0 \n",
    "    right=len(lst_a)\n",
    "    \n",
    "    while left<right:\n",
    "        middle = left+ ((right - left)//2)\n",
    "        if lst_a[middle] == target:\n",
    "            return lst_b[middle]\n",
    "        if lst_a[middle] < target:\n",
    "            if lst_a[middle+1] >= target:\n",
    "                idx_g = get_closer_num(lst_a, middle, middle+1, target)\n",
    "                return lst_b[idx_g]\n",
    "            else:\n",
    "                left = middle+1\n",
    "        if lst_a[middle] > target:\n",
    "            if lst_a[middle-1] <= target:\n",
    "                idx_g = get_closer_num(lst_a, middle-1, middle, target)\n",
    "                return lst_b[idx_g]\n",
    "            else:\n",
    "                right = middle\n",
    "\n",
    "# Equation 7. Given sigma, eta and beta, we get delta. \n",
    "# Note that since beta* is a function of sigma and eta, delta is a function of sigma and eta too. \n",
    "def get_delta(sigma, eta, beta):\n",
    "    part1 = sigma - (sigma-1)*(beta*eta+(1-beta)*(1-eta))\n",
    "    part2 = (((1/beta)**eta) * ((1/(1-beta))**(1-eta)))**(1-sigma)\n",
    "    delta = part1*part2\n",
    "    return delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0b1477",
   "metadata": {},
   "source": [
    "### P3. Simulate the bunching pattern and see how the firm-level outcomes would be like.\n",
    "\n",
    "The firm-level outcomes can be expressed with:\n",
    "\\begin{gather}\n",
    "    \\frac{\\tilde{h}}{\\tilde{m}} = \\frac{w_{m} \\beta \\eta}{w_{h} (1-\\beta) (1-\\eta)}  \\tag{15}\\\\ \n",
    "    \\tilde{p}(\\varphi) = \\frac{\\sigma}{\\sigma-1}\n",
    "                         \\left(\\frac{w_{h}}{\\beta \\eta}\\right)^{\\eta}\n",
    "                         \\left(\\frac{w_{m}}{(1-\\beta)(1-\\eta)}\\right)^{1-\\eta}\n",
    "                         \\frac{1}{\\varphi}    \\tag{17}\\\\\n",
    "    \\tilde{x}(\\varphi) = \\tilde{p}(\\varphi)^{1-\\sigma}P^{\\sigma-1}X(1-\\tau)^{\\sigma} \\tag{16} \\\\\n",
    "    \\tilde{h}   = \\frac{\\sigma-1}{\\sigma} \\frac{\\beta \\eta}{w_{h}}\\tilde{x}(\\varphi)  \\tag{19} \\\\\n",
    "    \\tilde{m}   = \\frac{\\sigma-1}{\\sigma} \\frac{(1-\\beta)(1- \\eta)}{w_{m}}\\tilde{x}(\\varphi)  \\tag{18} \\\\\n",
    "    \\tilde{\\pi} = \\left[ 1-\\frac{\\sigma-1}{\\sigma}(\\beta \\eta +(1-\\beta)(1-\\eta)) \\right] \\tilde{x} \\tag{*}\n",
    "\\end{gather}\n",
    "\n",
    "With equation (6), we get $\\delta$ :\n",
    "\\begin{equation}\n",
    "    \\delta(\\sigma, \\eta, \\beta) = [\\sigma-(\\sigma-1)(\\beta\\eta+(1-\\beta)(1-\\eta))]\n",
    "     [(\\frac{1}{\\beta})^{\\eta} (\\frac{1}{1-\\beta})^{1-\\eta}]^{1-\\sigma}  \\qquad(6)\n",
    "\\end{equation}\n",
    "\n",
    "Then we use equation (7). Here we need to see whether:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\delta(\\sigma, \\eta, \\beta^{*}) \\geq (\\delta(\\sigma, \\eta, \\underline{\\beta})-c) [\\frac{1-\\tau^{L}}{1-\\tau^{H}}]^{\\sigma}  \\qquad (7)\n",
    "\\end{equation}\n",
    "\n",
    "Note that:\n",
    "\\begin{equation}\n",
    "    p^{*}(\\varphi) = \\frac{\\sigma}{\\sigma-1} (\\frac{w_{h}}{\\eta})^{\\eta}  (\\frac{w_{m}}{1-\\eta})^{1-\\eta} \\frac{1}{\\varphi}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394ea53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equation 7. Given sigma, eta and beta, we get delta. \n",
    "# Note that since beta* is a function of sigma and eta, delta is a function of sigma and eta too. \n",
    "def get_delta(sigma, eta, beta):\n",
    "    part1 = sigma - (sigma-1)*(beta*eta+(1-beta)*(1-eta))\n",
    "    part2 = (((1/beta)**eta) * ((1/(1-beta))**(1-eta)))**(1-sigma)\n",
    "    delta = part1*part2\n",
    "    return delta\n",
    "\n",
    "# Equation (7). See if a firm would choose to bunch or not. \n",
    "def bunch_or_not(sigma, eta, beta_optimal, c, tau_L, tau_H):\n",
    "    \n",
    "    # Calculate the rhs of equation 9. \n",
    "    part1 = get_delta(sigma, eta, 0.25)-c\n",
    "    part2 = ((1-tau_L)/(1-tau_H))**sigma\n",
    "    RHS   = part1*part2\n",
    "    \n",
    "    # Calculate the LHS of equation (7). \n",
    "    LHS   = get_delta(sigma, eta, beta_optimal)\n",
    "    return int(LHS>=RHS)  # here 0 means it is optimal to bunch, 1 means to stay and not to bunch.\n",
    "\n",
    "# Input equation (15-19)\n",
    "def get_FirmVar(beta, eta, sigma, wh, wm, tau, varphi, P, X, bunch_or_not, cost):\n",
    "    \n",
    "    p_star  = (sigma/(sigma-1))* ((wh/eta)**eta) * ((wm/(1-eta))**(1-eta)) /varphi\n",
    "    p_tild  = (sigma/(sigma-1)) * (wh/(beta*eta))**eta * (wm/((1-beta)*(1-eta)))**(1-eta) / varphi\n",
    "    x_tild  = p_tild**(1-sigma) * P**(sigma-1) * X * (1-tau)**sigma\n",
    "    h_tild  = ((sigma-1)/sigma) * (beta*eta/wh) * x_tild\n",
    "    m_tild  = ((sigma-1)/sigma) * ((1-beta)*(1-eta)/wm) * x_tild\n",
    "    \n",
    "    # Note that if ther is no bunching (bunch_or_not == 1), the final Pi is just Pi_tild.\n",
    "    # If there is bunching (bunch_or_not == 0), then the final Pi should deduct the cost.\n",
    "    pi_tild = (get_delta(sigma, eta, beta)-cost*(1-bunch_or_not))* p_star**(1-sigma) * P**(sigma-1)* X*((1-tau)**sigma)/sigma\n",
    "\n",
    "    #return p_tild, x_tild, h_tild, m_tild, pi_tild\n",
    "    return pi_tild\n",
    "\n",
    "\n",
    "# Now we define a function to calculate optimal eta for these firms.\n",
    "\n",
    "def get_eta(beta, sigma):\n",
    "    # With beta_bins, calculate the LHS of (8). This is the list of targets we are searching for. \n",
    "    LHS_8 = np.array(beta)/(1-np.array(beta))\n",
    "\n",
    "    # Define the space of eta, which is the lst_b in the get_ans function. \n",
    "    eta_space = np.linspace(0.0001, 0.9999, 1000000)\n",
    "\n",
    "    # Calculate the RHS of equation 8, which is the lst_a in the get_ans function. \n",
    "    part1  = eta_space/(1-eta_space)\n",
    "    part2  = 1-(sigma-1)*(1-eta_space)/sigma \n",
    "    part3  = 1- (sigma-1)*eta_space/sigma \n",
    "    RHS_8  = np.sqrt(part1*part2/part3)\n",
    "\n",
    "    eta_simul = np.zeros(len(beta))\n",
    "\n",
    "    for i in range(len(beta)): \n",
    "        eta_simul[i] = get_ans(RHS_8, eta_space, LHS_8[i])\n",
    "    \n",
    "    return eta_simul\n",
    "\n",
    "# We define a function to generate cost and productivity.\n",
    "def getCostVarphi(theta, mu_c, k, Rep_id):\n",
    "    # Generate adjustment cost and productivity.\n",
    "    # See the process of drawing these random numbers in \n",
    "    # section B.1 Online Appendix of James & Ariell (2015 CJE)\n",
    "    np.random.seed(1234+Rep_id)\n",
    "    copula_u = np.random.uniform(0,1,101310)\n",
    "\n",
    "    np.random.seed(123+Rep_id)\n",
    "    copula_x = np.random.uniform(0,1,101310)\n",
    "\n",
    "    copula_a = copula_x*(1-copula_x)\n",
    "    copula_b = theta + copula_a*((theta-1)**2)\n",
    "    copula_c = 2*copula_a*(copula_u*(theta**2)+1-copula_u) + theta*(1-2*copula_a)\n",
    "    copula_d = np.sqrt(theta)*np.sqrt(theta + 4*copula_a*copula_u*(1-copula_u)*((1-theta)**2))\n",
    "    copula_v = (copula_c-(1-2*copula_x)*copula_d)/(2*copula_b)\n",
    "\n",
    "    # We assume that cost is just a uniform distribution.\n",
    "    copula_cost = copula_u*mu_c\n",
    "\n",
    "    # Now we generate varphi based on U we draw.\n",
    "    # If U is drawn from a uniform distribution [0,1], and T = xm*U**(-1/k), then T is Pareto-Distributed.\n",
    "    copula_varphi = xm*((1-copula_v)**(-1/k))\n",
    "\n",
    "    cost_varphi_df = pd.DataFrame(data={'copula_cost':copula_cost, 'copula_varphi':copula_varphi})\n",
    "\n",
    "    # Winsorize the sample. Drop the bottom 2% and top 1% sample.\n",
    "    top99   = np.quantile(copula_varphi, 0.99)\n",
    "    bottom1 = np.quantile(copula_varphi, 0.01)\n",
    "    eta_varphi_winsorized = copy.deepcopy(cost_varphi_df[(cost_varphi_df['copula_varphi']<top99)&(cost_varphi_df['copula_varphi']>bottom1)])\n",
    "    eta_varphi_winsorized.reset_index(drop=True, inplace=True)\n",
    "    cost_simul   = eta_varphi_winsorized['copula_cost'].values[:a1]\n",
    "    varphi_simul = eta_varphi_winsorized['copula_varphi'].values[:a1]\n",
    "\n",
    "    return cost_simul, varphi_simul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99944194",
   "metadata": {},
   "source": [
    "#### Read in some parameters and $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfec7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read in bins (beta), eta data and see their distributions. \n",
    "beta_eta_df   = pd.read_csv(path+'beta_eta.csv')\n",
    "beta_all      = np.array(beta_eta_df['beta_bins'])\n",
    "#eta_all      = np.array(beta_eta_df['eta_bins'])\n",
    "\n",
    "# Read in bins, real distribution and counterfactual distributions of firms we use in the bunching estimation.\n",
    "bunching_df   = pd.read_excel(path+'R2_pre2008June122023.xlsx')\n",
    "\n",
    "bins_bunching = np.array(bunching_df['R2_bins'])\n",
    "C_bunching    = np.array(bunching_df['R2_C_all'])  # Actual probability of firms falling into each bins.\n",
    "h_bunching    = np.array(bunching_df['h'])         # Counterfactual probability of firms falling into each bins.\n",
    "p             = 4                                  # Polynomial.\n",
    "minD          = 0.01                               # Minimum of the bins we use.\n",
    "\n",
    "tau_L         = np.float64(0.15)\n",
    "tau_H         = np.float64(0.225)\n",
    "w_h           = 1\n",
    "w_m           = 1\n",
    "big_p         = 1\n",
    "big_x         = 1\n",
    "xm            = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebbe3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that helps us to calculate the conditional expectation of Beta.\n",
    "def get_Beta_conditional_expectation(group_name, count_var, target_df):\n",
    "    \n",
    "    # Calculate the number of firms in each bin.\n",
    "    temp_counts = target_df.groupby(group_name)[count_var].count().reset_index()\n",
    "    temp_counts.rename(columns={count_var:'counts'}, inplace=True)\n",
    "    \n",
    "    # Calculate the probability of firms falling into each bin.\n",
    "    temp_counts['probs'] = temp_counts['counts']/np.sum(temp_counts['counts'])\n",
    "    \n",
    "    # Calculate the conditional probability of firms with FDI share below 25%.\n",
    "    temp_counts = copy.deepcopy(temp_counts[(temp_counts[group_name]<=25)&(temp_counts[group_name]>=7)])\n",
    "    temp_counts['conditional_prob'] = temp_counts['probs']/np.sum(temp_counts['probs'])\n",
    "    \n",
    "    # Calculate conditional expectation.\n",
    "    expetation = np.sum((temp_counts[group_name]+1)*temp_counts['conditional_prob']/100)\n",
    "    \n",
    "    # Calculate frac_nb (staying ratio)\n",
    "    temp_counts = copy.deepcopy(temp_counts[(temp_counts[group_name]<25)&(temp_counts[group_name]>=7)])\n",
    "    sum_probs   = np.sum(temp_counts['probs'])\n",
    "    # sum_probs   = np.sum(temp_counts['probs'][:-1])\n",
    "\n",
    "    \n",
    "    return expetation, sum_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e8ad38",
   "metadata": {},
   "source": [
    "#### Construct data moments and weighting matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3401296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# mean and covariance of the jump-down and the profit dispersion. \n",
    "# First read in the moment for the drop at the notch.  \n",
    "####################################################################################################\n",
    "\n",
    "rst_bootstrap100bins = pd.read_csv(path+'rst_bs100binDeFEbsample.csv')\n",
    "\n",
    "# Take out the estimated parameters of the bin-effect that we care about.\n",
    "bootstrapb_fdi_24    = rst_bootstrap100bins['b_fdi_24'].values\n",
    "bootstrapb_fdi_25    = rst_bootstrap100bins['b_fdi_25'].values\n",
    "bootstrapb_fdi_26    = rst_bootstrap100bins['b_fdi_26'].values\n",
    "bootstrapb_fdi_27    = rst_bootstrap100bins['b_fdi_27'].values\n",
    "\n",
    "# Read in the firm distribution data. \n",
    "rst_bootstrapBinDistribution = pd.read_csv(path+'rst_bootstrapBinDistribution.csv')\n",
    "bootstrap_counts_25          = rst_bootstrapBinDistribution['counts_25'].values\n",
    "bootstrap_counts_26          = rst_bootstrapBinDistribution['counts_26'].values\n",
    "# Calculate the weight.\n",
    "bootstrap_weight_25          = bootstrap_counts_25/(bootstrap_counts_25+bootstrap_counts_26)\n",
    "bootstrap_weight_26          = bootstrap_counts_26/(bootstrap_counts_25+bootstrap_counts_26)\n",
    "\n",
    "# Calculate the weighted sum of the jump at the notch.\n",
    "weighted_drop     = bootstrapb_fdi_25*bootstrap_weight_25 + bootstrapb_fdi_26*bootstrap_weight_26\n",
    "\n",
    "# Calculate the bootstrapped profit drop at the notch.\n",
    "left_drop_BS  = bootstrapb_fdi_24-weighted_drop\n",
    "right_drop_BS = bootstrapb_fdi_27-weighted_drop\n",
    "\n",
    "################################################################################\n",
    "# Calculate the dispersion of the profits in the data.\n",
    "################################################################################\n",
    "# Read in the bootstrapped results.\n",
    "rst_bootstrap20bins = pd.read_csv(path+'rst_bs20binDeFEbsample.csv')\n",
    "bootstrapb_fdi_1    = rst_bootstrap20bins['b_fdi_1'].values\n",
    "bootstrapb_fdi_9    = rst_bootstrap20bins['b_fdi_9'].values\n",
    "profitDis_BS        = bootstrapb_fdi_1-bootstrapb_fdi_9\n",
    "\n",
    "################################################################################\n",
    "# Calculate the tfp moments.\n",
    "################################################################################\n",
    "# We use the ratio of 25 percentile/50 percentile, and 75 percentile/50 percentile.\n",
    "rst_bootstrapTFP = pd.read_csv(path+'rst_bootstrapTFP.csv')\n",
    "tfp_p_25         = rst_bootstrapTFP['p_25'].values\n",
    "tfp_p_50         = rst_bootstrapTFP['p_50'].values\n",
    "tfp_p_75         = rst_bootstrapTFP['p_75'].values\n",
    "\n",
    "# Calculate the ratio.\n",
    "lntfp_2550_BS    = tfp_p_25/tfp_p_50\n",
    "lntfp_7550_BS    = tfp_p_75/tfp_p_50\n",
    "\n",
    "################################################################################\n",
    "# Moment of the stayer ratio and increased FDI share.\n",
    "################################################################################\n",
    "bootstrapBucnhing = pd.read_csv(path+'bootstrap_bunching12June2023.csv')\n",
    "frac_nb_BS        = bootstrapBucnhing['frac_nb_B'].values\n",
    "Dd_BS             = bootstrapBucnhing['Dd_B'].values\n",
    "\n",
    "################################################################################\n",
    "# Collect the moments and construct variance-covariance matrix.\n",
    "################################################################################\n",
    "# Put all bootstrapped data together. \n",
    "BS_results      = np.zeros((2000, 7))\n",
    "BS_results[:,0] = left_drop_BS\n",
    "BS_results[:,1] = right_drop_BS\n",
    "BS_results[:,2] = profitDis_BS\n",
    "\n",
    "BS_results[:,3] = lntfp_2550_BS\n",
    "BS_results[:,4] = lntfp_7550_BS\n",
    "\n",
    "BS_results[:,5] = frac_nb_BS\n",
    "BS_results[:,6] = Dd_BS\n",
    "\n",
    "# get data moments\n",
    "data_moments = np.around(BS_results.mean(axis=0),4)\n",
    "\n",
    "# calculate the var matrix.\n",
    "var_matrix   = np.zeros((7,7))\n",
    "cov_regress  = np.array(pd.DataFrame(BS_results[:,:3]).cov())\n",
    "cov_lntfp    = np.array(pd.DataFrame(BS_results[:,3:5]).cov())\n",
    "cov_bunching = np.array(pd.DataFrame(BS_results[:,5:7]).cov())\n",
    "\n",
    "# Store those matrix into the var_matrix.\n",
    "var_matrix[:3, :3]   = cov_regress\n",
    "var_matrix[3:5, 3:5] = cov_lntfp\n",
    "var_matrix[5:7, 5:7] = cov_bunching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "865a715a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008581</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.005671</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000168e-07</td>\n",
       "      <td>-9.526837e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.526837e-09</td>\n",
       "      <td>2.528222e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.007888</td>\n",
       "      <td>-0.001867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.001867</td>\n",
       "      <td>0.001202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2             3             4         5  \\\n",
       "0  0.008581  0.000400 -0.000014  0.000000e+00  0.000000e+00  0.000000   \n",
       "1  0.000400  0.005671  0.000114  0.000000e+00  0.000000e+00  0.000000   \n",
       "2 -0.000014  0.000114  0.005088  0.000000e+00  0.000000e+00  0.000000   \n",
       "3  0.000000  0.000000  0.000000  2.000168e-07 -9.526837e-09  0.000000   \n",
       "4  0.000000  0.000000  0.000000 -9.526837e-09  2.528222e-07  0.000000   \n",
       "5  0.000000  0.000000  0.000000  0.000000e+00  0.000000e+00  0.007888   \n",
       "6  0.000000  0.000000  0.000000  0.000000e+00  0.000000e+00 -0.001867   \n",
       "\n",
       "          6  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.000000  \n",
       "5 -0.001867  \n",
       "6  0.001202  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(var_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7627526d",
   "metadata": {},
   "source": [
    "### Calculate the simulated moments.\n",
    "\n",
    "#### We first simulate 100,000 $\\beta$. Note that $\\beta$ does not change with the parameters in the following part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81887fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of simulated firms: 99277\n",
      "Number of counterfactual firms: 99321\n",
      "Note that there should be less than 100,000 firms since we exclude firms with fdi_share>0.99, and fdi_share less than 0.02.\n",
      "There is some slight difference between the number of counterfactual and simulated firms because we round the floats to integers.\n"
     ]
    }
   ],
   "source": [
    "# Read in b that we estimated from the bunching part.\n",
    "b = np.array(pd.read_excel(path+'outputJune122023/R5_pre2008June122023.xlsx')['b'])\n",
    "\n",
    "# Now we want to get the distribution of eta, and try to fit it to a beta-distribution. \n",
    "# In order to do so, we omit all the round number effects. \n",
    "polynomial_beta = []\n",
    "for i in range(p+1):\n",
    "    polynomial_beta.append(bins_bunching**i)\n",
    "polynomial_beta = np.array(polynomial_beta).T\n",
    "\n",
    "# Multiply b and polynomial_beta together.\n",
    "distribution_noRN = np.dot(polynomial_beta, b[:p+1].reshape(p+1,-1))\n",
    "distribution_noRN = distribution_noRN.ravel()\n",
    "\n",
    "# Now we simulate 100,000 firms. \n",
    "# The first step is to generate 100,000 betas according to the counterfactual distribution of Beta.\n",
    "# Now we know the probability of etas falling into each bins, we simulate data of eta based on this.\n",
    "# cf means counterfactual here.\n",
    "beta_cf_simul = []\n",
    "\n",
    "# We cut the last bin (0.99-1) out since there would be a lot of extrem values in that bin when we calculate eta.\n",
    "bins_bunching = np.array(bunching_df['R2_bins'])\n",
    "\n",
    "# We get lower and uppper bond of each bin, and sample beta within each bin.\n",
    "beta_temp  = list(bins_bunching)\n",
    "beta_temp.append(np.float64(1.0))\n",
    "total_firm_num = 100000\n",
    "\n",
    "for i in range(len(beta_temp)-1):\n",
    "    lb_bin  = beta_temp[i]     # lower bond of the bin\n",
    "    ub_bin  = beta_temp[i+1]   # upper bond of the bin \n",
    "    len_bin = ub_bin-lb_bin\n",
    "    \n",
    "    # Number of firms in each bin, each should have an beta that lies within the range of the bin. \n",
    "    # Here we assume that in each bin, beta is uniformly distributed.\n",
    "    bin_firm_num = int(h_bunching[i]*total_firm_num)\n",
    "    np.random.seed(123+i)\n",
    "    \n",
    "    # Random.random_sample generates uniformly-distributed sample in [0,1). So here we need to multiply them\n",
    "    # by the length of each bin, and add lb_bin to it. \n",
    "    rand_uniform   = np.random.random_sample(size = bin_firm_num)\n",
    "    beta_each_bin  = list(rand_uniform*len_bin + lb_bin)\n",
    "    beta_cf_simul += beta_each_bin\n",
    "\n",
    "# Now we put all the simulated_beta_star into each bins.\n",
    "bins_temp = np.arange(2,101)/100\n",
    "\n",
    "# Here the ID of the bins starts from 1 (not 0). So the first bin [0.02,0.03) has a simul_bin_id==1.\n",
    "simul_bin_id = np.digitize(beta_cf_simul, bins_temp, right=False)\n",
    "\n",
    "# Count how many betas are there in each bin.\n",
    "simul_beta_df      = pd.DataFrame(data={'beta_cf_simul':np.array(beta_cf_simul), \n",
    "                                        'simul_bin_id':np.array(simul_bin_id)+1})\n",
    "simul_betaCount_df = simul_beta_df.groupby('simul_bin_id')['beta_cf_simul'].count().reset_index()\n",
    "simul_betaCount_df.rename(columns={'beta_cf_simul':'count'}, inplace=True)\n",
    "\n",
    "# Count the number of firms that may choose to bunch (FDI_SAHRE<25)\n",
    "num_possible_bunchFirm = np.sum(simul_betaCount_df[simul_betaCount_df['simul_bin_id']<25]['count'])\n",
    "\n",
    "# Let's check how our simulated beta looks like. \n",
    "a1 = len(beta_cf_simul)\n",
    "a2 = int(np.sum(h_bunching)*total_firm_num)\n",
    "print('Number of simulated firms: {0}'.format(a1))\n",
    "print('Number of counterfactual firms: {0}'.format(a2))\n",
    "print('Note that there should be less than 100,000 firms since we exclude firms with fdi_share>0.99, and fdi_share less than 0.02.')\n",
    "print('There is some slight difference between the number of counterfactual and simulated firms because we round the floats to integers.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa29494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the simulated moments.\n",
    "def getSimulMMt(sigma, theta, k, mu_c, Reps):\n",
    "    # Store the results.\n",
    "    simulated_mmtRst = np.zeros(7)\n",
    "    \n",
    "    # Generate eta, given optimal beta.\n",
    "    # Note that when beta>0.99, there would be a lot of extreme values when we calculate eta.\n",
    "    # For simplicity, if firms have betas>0.99, we replace them to be 0.99.\n",
    "    simul_beta_df.loc[simul_beta_df['beta_cf_simul']>0.99, ['beta_cf_simul']]=0.99\n",
    "    eta_simul = get_eta(simul_beta_df['beta_cf_simul'].values, sigma)\n",
    "    simul_beta_df['eta_simul'] = np.array(eta_simul)\n",
    "\n",
    "    # Generate simulated cost and varphi.\n",
    "    for Rep in range(Reps):\n",
    "        cost_simul, varphi_simul = getCostVarphi(theta, mu_c, k, Rep)\n",
    "        \n",
    "        # Pack simulated data into a dataFrame.\n",
    "        sim_firm_df = pd.DataFrame(data={'beta_cf_simul': simul_beta_df['beta_cf_simul'],\n",
    "                                         'simul_bin_id': simul_beta_df['simul_bin_id'],\n",
    "                                         'eta_simul': simul_beta_df['eta_simul'],\n",
    "                                         'cost_simul':cost_simul,\n",
    "                                         'varphi_simul': varphi_simul})\n",
    "\n",
    "        # Calculate the pre-tax profits without bunching.\n",
    "        # Start by giving all firms a low tax rate.\n",
    "        sim_firm_df['tau_noBunch'] = tau_L\n",
    "        # If the FDI share is below 0.25, replace the tax rate with a higher rate.\n",
    "        sim_firm_df.loc[sim_firm_df['beta_cf_simul']<0.25, ['tau_noBunch']] = tau_H\n",
    "\n",
    "        # Calculate post-tax profits when there is no bunching.\n",
    "        pi_noBunchpostTax = get_FirmVar(sim_firm_df['beta_cf_simul'], sim_firm_df['eta_simul'], \n",
    "                                        sigma, w_h, w_m, \n",
    "                                        sim_firm_df['tau_noBunch'], \n",
    "                                        sim_firm_df['varphi_simul'], \n",
    "                                        big_p, big_x, 1, 0)\n",
    "        \n",
    "        # Pre-tax profits when there is no bunching.\n",
    "        sim_firm_df['pi_noBunch'] = np.log(pi_noBunchpostTax/(1-sim_firm_df['tau_noBunch']))\n",
    "\n",
    "        # Now we look at firms bunching decisions. We first calculate the LHS and RHS of 7\n",
    "        # Calculate the rhs of equation 7 \n",
    "\n",
    "        part1 = get_delta(sigma, sim_firm_df['eta_simul'], 0.25)-sim_firm_df['cost_simul']\n",
    "        part2 = ((1-tau_L)/(1-tau_H))**sigma\n",
    "        RHS   = part1*part2\n",
    "\n",
    "        # Calculate the LHS of equation (7). \n",
    "        LHS   = get_delta(sigma, sim_firm_df['eta_simul'], sim_firm_df['beta_cf_simul'])\n",
    "        bunch_decision = (LHS>=RHS).astype(int) # here 0 means it is optimal to bunch, 1 means to stay and not to bunch.\n",
    "\n",
    "        # Compile bunching decision into the dataframe.\n",
    "        sim_firm_df['bunch_decision'] = bunch_decision\n",
    "\n",
    "        # When sim_firm_df['beta_cf_simul']>=0.25, there is no bunching.\n",
    "        sim_firm_df.loc[sim_firm_df['beta_cf_simul']>=0.25, ['bunch_decision']]=1\n",
    "\n",
    "        # Let's create a column of firms' final beta: when there is no bunching, final_beta = beta_cf_simul;\n",
    "        # When there is bunching, final_beta = 0.25.\n",
    "        sim_firm_df['final_beta'] = sim_firm_df['beta_cf_simul']\n",
    "        sim_firm_df.loc[sim_firm_df['bunch_decision']==0, ['final_beta']] = 0.25\n",
    "\n",
    "        # Calculate final_bin_ID.\n",
    "        # Here the ID of the bins starts from 1 (not 0). So the first bin [0.02,0.03) has a simul_bin_id==1.\n",
    "        sim_firm_df['final_bin_id'] = np.digitize(sim_firm_df['final_beta'], bins_temp, right=False)\n",
    "        sim_firm_df['final_bin_id'] = sim_firm_df['final_bin_id']+1\n",
    "\n",
    "        # Note that eta does not change, so final_eta = eta_simul.\n",
    "        sim_firm_df['final_eta'] = sim_firm_df['eta_simul']\n",
    "\n",
    "        # Generate final_tau column. If final_beta>=0.25, then final_tau=tau_L. If final_beta<0.25, final_tau= tau_H.\n",
    "        sim_firm_df['final_tau'] = tau_H\n",
    "        sim_firm_df.loc[sim_firm_df['final_beta']>=0.25, ['final_tau']]=tau_L\n",
    "\n",
    "        # Calculate simulated profit before tax, with bunching. \n",
    "        pi_tild = get_FirmVar(sim_firm_df['final_beta'],sim_firm_df['final_eta'],\n",
    "                              sigma, w_h, w_m, \n",
    "                              sim_firm_df['final_tau'],sim_firm_df['varphi_simul'],\n",
    "                              big_p, big_x, \n",
    "                              sim_firm_df['bunch_decision'],sim_firm_df['cost_simul'],)\n",
    "        \n",
    "        # Calculate profits before tax with bunching.\n",
    "        sim_firm_df['pi_preTax'] = np.log(pi_tild/(1-sim_firm_df['final_tau']))\n",
    "\n",
    "        # Calculate the mean of pi in each bins and de-mean.\n",
    "        sub_mean_pi = pd.DataFrame(sim_firm_df.groupby('final_bin_id')['pi_preTax'].mean()).reset_index()\n",
    "\n",
    "        # Take out the bins 0.24, 0.25,0.26.\n",
    "        profit_bin2426 = sub_mean_pi[(sub_mean_pi['final_bin_id']>=24)&(sub_mean_pi['final_bin_id']<=26)]['pi_preTax'].values\n",
    "\n",
    "        # Calculate the jump. Note that we also need the profit in 0.24 to be higher than the profit in 0.26.\n",
    "        left_drop  = profit_bin2426[0] - profit_bin2426[1]\n",
    "        right_drop = profit_bin2426[2] - profit_bin2426[1]\n",
    "        over_drop  = profit_bin2426[0] - profit_bin2426[2]\n",
    "        #simulated_drop_moment = [left_drop, right_drop, over_drop]\n",
    "        simulated_drop_moment = [left_drop, right_drop]\n",
    "\n",
    "        ### Calculate the increase in Beta and stayer_mmt.\n",
    "        notch_bin = 25\n",
    "        minBin    = 1\n",
    "        \n",
    "        # Calculate the counterfactual distribution of firms (corresponding to h in the bunching estimation).\n",
    "        temp_h      = sim_firm_df.groupby('simul_bin_id')['beta_cf_simul'].count().reset_index()\n",
    "        temp_h['h'] = temp_h['beta_cf_simul']/np.sum(temp_h['beta_cf_simul'])\n",
    "\n",
    "        # Calculate the 'observed' distribution of firms (corresponding to C in the bunching estimation).\n",
    "        # Note that here, the 'observed' distribution is the distribution of firms with bunching.\n",
    "        temp_C      = sim_firm_df.groupby('final_bin_id')['beta_cf_simul'].count().reset_index()\n",
    "        temp_C['C'] = temp_C['beta_cf_simul']/np.sum(temp_C['beta_cf_simul'])\n",
    "        \n",
    "        # Theoretically, all firms should have bunched to the right. However due to firction cost, \n",
    "        # some firms still stay to the left. Here we calculate the ratio of real stayers over conterfactual stayers. \n",
    "        # The higher the ratio, the higher the frition cost \n",
    "        frac_nb = np.sum(temp_C[temp_C['final_bin_id']<notch_bin]['C'])/np.sum(temp_h[temp_h['simul_bin_id']<notch_bin]['h'])\n",
    "\n",
    "        # b_Bstat: the upper bound of bins of the range (minD, notch].\n",
    "        b_Bstat = np.arange(minBin+1, notch_bin+1)/100+0.01\n",
    "\n",
    "        # c_Bstat: conditional probability of \"observed\" firm distribution\n",
    "        c_Bstat = np.array(temp_C[temp_C['final_bin_id']<= notch_bin]['C'])/np.sum(temp_C[temp_C['final_bin_id']<= notch_bin]['C'])\n",
    "\n",
    "        # hh: conditional probability of \"counter-factual\" firm distribution\n",
    "        hh = np.array(temp_h[temp_h['simul_bin_id']<= notch_bin]['h'])/np.sum(temp_h[temp_h['simul_bin_id']<= notch_bin]['h'])\n",
    "\n",
    "        # Calculate Dd\n",
    "        Dd = np.sum(b_Bstat*(c_Bstat - hh))/np.sum(b_Bstat*hh)\n",
    "        \n",
    "        stayer_mmt    = [frac_nb]\n",
    "        beta_increase = [Dd]\n",
    "\n",
    "        ### Calculate the simulated TFP moment.\n",
    "        lnsimul_TFP          = np.log(varphi_simul)\n",
    "        lnsimul_TFP_2550     = np.percentile(lnsimul_TFP, 0.25)/np.percentile(lnsimul_TFP, 0.5)\n",
    "        lnsimul_TFP_7550     = np.percentile(lnsimul_TFP, 0.75)/np.percentile(lnsimul_TFP, 0.5)\n",
    "        simulated_TFP_moment = [lnsimul_TFP_2550, lnsimul_TFP_7550]  \n",
    "        \n",
    "        # Calculate the profit dispersion.\n",
    "        pi_preTaxBin1       = np.mean(sim_firm_df[sim_firm_df['final_bin_id']<5]['pi_preTax'])\n",
    "        pi_preTaxBin50      = np.mean(sim_firm_df[(sim_firm_df['final_bin_id']<50)&\n",
    "                                                  (sim_firm_df['final_bin_id']>=45)]['pi_preTax'])\n",
    "        simul_pi_dispersion = [pi_preTaxBin1-pi_preTaxBin50]\n",
    "\n",
    "        simulated_mmt = np.array(simulated_drop_moment+ simul_pi_dispersion + simulated_TFP_moment + stayer_mmt\n",
    "                                 + beta_increase )\n",
    "        simulated_mmtRst += simulated_mmt\n",
    "        \n",
    "        \n",
    "    return simulated_mmtRst/Reps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5630f694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26208171 0.06304872 1.2047081  0.83280396 1.16251036 0.59697406\n",
      " 0.19901692]\n",
      "[0.2228 0.0647 1.3992 0.83   1.16   0.4609 0.2082]\n"
     ]
    }
   ],
   "source": [
    "# Test our code.\n",
    "simulated_mmtRst = getSimulMMt(2.2, 20, 2.1, 0.35, 10)\n",
    "print(simulated_mmtRst)\n",
    "print(data_moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a0bff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance between simulated conditions and data conditions.\n",
    "# We first specify the weighting matrix.\n",
    "w = np.linalg.inv(var_matrix)\n",
    "\n",
    "# Define the objective function.\n",
    "def get_MomentCondition(Paras, Reps):\n",
    "    sigma    = Paras[0]\n",
    "    theta    = Paras[1]\n",
    "    k        = Paras[2]\n",
    "    mu_c     = Paras[3]\n",
    "    SimulMMt = getSimulMMt(sigma, theta, k, mu_c, Reps)\n",
    "    dif      = SimulMMt-data_moments\n",
    "    distance = np.matmul(np.matmul(dif, w), dif.T)\n",
    "    return float(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fed1f669",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     f(X)         sigma      theta     k          mu_c     \n",
      "   1  50.782136   2.310000   20.000000   2.100000   0.350000\n",
      "   2  50.782136   2.310000   20.000000   2.100000   0.350000\n",
      "   3  50.782136   2.310000   20.000000   2.100000   0.350000\n",
      "   4  50.782136   2.310000   20.000000   2.100000   0.350000\n",
      "   5  43.031994   2.267031   20.062500   2.111484   0.351914\n",
      "   6  39.731062   2.305273   20.046875   2.147988   0.333936\n",
      "   7  39.452673   2.313652   20.054688   2.077236   0.342925\n",
      "   8  39.452673   2.313652   20.054688   2.077236   0.342925\n",
      "   9  39.452673   2.313652   20.054688   2.077236   0.342925\n",
      "  10  39.452673   2.313652   20.054688   2.077236   0.342925\n",
      "  11  39.452673   2.313652   20.054688   2.077236   0.342925\n",
      "  12  39.452673   2.313652   20.054688   2.077236   0.342925\n",
      "  13  38.874767   2.329773   20.051783   2.113930   0.333926\n",
      "  14  38.874767   2.329773   20.051783   2.113930   0.333926\n",
      "  15  38.874767   2.329773   20.051783   2.113930   0.333926\n",
      "  16  38.874767   2.329773   20.051783   2.113930   0.333926\n",
      "  17  38.874767   2.329773   20.051783   2.113930   0.333926\n",
      "  18  38.874767   2.329773   20.051783   2.113930   0.333926\n",
      "  19  38.874767   2.329773   20.051783   2.113930   0.333926\n",
      "  20  38.864980   2.334999   20.050178   2.141963   0.326387\n",
      "  21  38.655687   2.335640   20.053562   2.129110   0.327479\n",
      "  22  38.655687   2.335640   20.053562   2.129110   0.327479\n",
      "  23  38.636883   2.339555   20.052782   2.124261   0.327924\n",
      "  24  38.636883   2.339555   20.052782   2.124261   0.327924\n",
      "  25  38.636883   2.339555   20.052782   2.124261   0.327924\n",
      "  26  38.636883   2.339555   20.052782   2.124261   0.327924\n",
      "  27  38.618830   2.339485   20.053965   2.133511   0.325636\n",
      "  28  38.618830   2.339485   20.053965   2.133511   0.325636\n",
      "  29  38.615441   2.346659   20.051958   2.136161   0.323716\n",
      "  30  38.605171   2.343815   20.052345   2.134449   0.324417\n",
      "  31  38.567597   2.344994   20.052538   2.146037   0.321836\n",
      "  32  38.554168   2.348339   20.053031   2.138604   0.322051\n",
      "  33  38.554168   2.348339   20.053031   2.138604   0.322051\n",
      "  34  38.554168   2.348339   20.053031   2.138604   0.322051\n",
      "  35  38.554168   2.348339   20.053031   2.138604   0.322051\n",
      "  36  38.554168   2.348339   20.053031   2.138604   0.322051\n",
      "  37  38.554168   2.348339   20.053031   2.138604   0.322051\n",
      "  38  38.544642   2.346888   20.053317   2.145538   0.321117\n",
      "  39  38.544642   2.346888   20.053317   2.145538   0.321117\n",
      "  40  38.543298   2.348343   20.052905   2.143410   0.321371\n",
      "  41  38.542743   2.349564   20.052981   2.146687   0.320211\n",
      "  42  38.542743   2.349564   20.052981   2.146687   0.320211\n",
      "  43  38.537771   2.346750   20.052972   2.148352   0.320784\n",
      "  44  38.537771   2.346750   20.052972   2.148352   0.320784\n",
      "  45  38.537771   2.346750   20.052972   2.148352   0.320784\n",
      "  46  38.537771   2.346750   20.052972   2.148352   0.320784\n",
      "  47  38.536107   2.348542   20.053068   2.147252   0.320460\n",
      "  48  38.536107   2.348542   20.053068   2.147252   0.320460\n",
      "  49  38.536107   2.348542   20.053068   2.147252   0.320460\n",
      "  50  38.534565   2.344965   20.053011   2.151099   0.320870\n",
      "  51  38.534565   2.344965   20.053011   2.151099   0.320870\n",
      "  52  38.534565   2.344965   20.053011   2.151099   0.320870\n",
      "  53  38.534565   2.344965   20.053011   2.151099   0.320870\n",
      "  54  38.534565   2.344965   20.053011   2.151099   0.320870\n",
      "  55  38.534565   2.344965   20.053011   2.151099   0.320870\n",
      "  56  38.533802   2.344482   20.052952   2.153400   0.320616\n",
      "  57  38.530937   2.346500   20.053015   2.151042   0.320405\n",
      "  58  38.530937   2.346500   20.053015   2.151042   0.320405\n",
      "  59  38.530937   2.346500   20.053015   2.151042   0.320405\n",
      "  60  38.530937   2.346500   20.053015   2.151042   0.320405\n",
      "  61  38.530592   2.345964   20.052968   2.151995   0.320368\n",
      "  62  38.530592   2.345964   20.052968   2.151995   0.320368\n",
      "  63  38.529259   2.345705   20.052980   2.152552   0.320364\n",
      "  64  38.529259   2.345705   20.052980   2.152552   0.320364\n",
      "  65  38.529259   2.345705   20.052980   2.152552   0.320364\n",
      "  66  38.529259   2.345705   20.052980   2.152552   0.320364\n",
      "  67  38.529259   2.345705   20.052980   2.152552   0.320364\n",
      "  68  38.528371   2.346312   20.052985   2.151615   0.320345\n",
      "  69  38.528371   2.346312   20.052985   2.151615   0.320345\n",
      "  70  38.528371   2.346312   20.052985   2.151615   0.320345\n",
      "  71  38.528371   2.346312   20.052985   2.151615   0.320345\n",
      "  72  38.528371   2.346312   20.052985   2.151615   0.320345\n",
      "  73  38.528371   2.346312   20.052985   2.151615   0.320345\n",
      "  74  38.528371   2.346312   20.052985   2.151615   0.320345\n",
      "  75  38.528371   2.346312   20.052985   2.151615   0.320345\n",
      "  76  38.528371   2.346312   20.052985   2.151615   0.320345\n",
      "  77  38.528371   2.346312   20.052985   2.151615   0.320345\n",
      "  78  38.528371   2.346312   20.052985   2.151615   0.320345\n",
      "  79  38.528371   2.346312   20.052985   2.151615   0.320345\n",
      "  80  38.528371   2.346312   20.052985   2.151615   0.320345\n",
      "  81  38.528371   2.346312   20.052985   2.151615   0.320345\n",
      "  82  38.528371   2.346312   20.052985   2.151615   0.320345\n",
      "  83  38.528105   2.346185   20.052981   2.151857   0.320340\n",
      "  84  38.528105   2.346185   20.052981   2.151857   0.320340\n",
      "  85  38.528105   2.346185   20.052981   2.151857   0.320340\n",
      "  86  38.528105   2.346185   20.052981   2.151857   0.320340\n",
      "  87  38.528105   2.346185   20.052981   2.151857   0.320340\n",
      "  88  38.528105   2.346185   20.052981   2.151857   0.320340\n",
      "  89  38.528105   2.346185   20.052981   2.151857   0.320340\n",
      "  90  38.528105   2.346185   20.052981   2.151857   0.320340\n",
      "  91  38.528076   2.346160   20.052981   2.151907   0.320339\n",
      "  92  38.528076   2.346160   20.052981   2.151907   0.320339\n",
      "Duration: 0:08:32.187450\n"
     ]
    }
   ],
   "source": [
    "params_ini = [2.2, 20, 2.1, 0.35]\n",
    "Reps       = 5\n",
    "\n",
    "Nfeval = 1\n",
    "\n",
    "def callbackF(xk):\n",
    "    global Nfeval\n",
    "    print ('{0:4d} {1: 3.6f}  {2: 3.6f}  {3: 3.6f}  {4: 3.6f}  {5: 3.6f}'\\\n",
    "           .format(Nfeval, get_MomentCondition(xk, Reps), xk[0], xk[1], xk[2], xk[3]))\n",
    "    Nfeval += 1\n",
    "\n",
    "print  ('{0:4s}     {1:9s}   {2:9s}  {3:9s}  {4:9s}  {5:9s}'\\\n",
    "        .format('Iter', 'f(X)',  ' sigma', ' theta',  'k', 'mu_c'))\n",
    "\n",
    "start_time = datetime.now()\n",
    "betas = minimize(get_MomentCondition, x0=params_ini, \n",
    "                 args=(Reps), \n",
    "                 method='Nelder-Mead', \n",
    "                 tol=0.0001,\n",
    "                 callback = callbackF, \n",
    "                 options={'maxiter':1000})\n",
    "\n",
    "final_sigma1e51, final_theta1e51, final_k1e51, final_muc1e51 = betas['x']\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91e9e633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29651663 0.04156448 1.37693757 0.83285678 1.16225029 0.54995858\n",
      " 0.22144749]\n",
      "[0.2228 0.0647 1.3992 0.83   1.16   0.4609 0.2082]\n"
     ]
    }
   ],
   "source": [
    "# Test our code.\n",
    "simulated_mmtRst = getSimulMMt(final_sigma1e51, final_theta1e51, final_k1e51, final_muc1e51, 10)\n",
    "print(simulated_mmtRst)\n",
    "print(data_moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0585c789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     f(X)         sigma      theta     k          mu_c     \n",
      "   1  10.198900   2.310000   17.800000   2.300000   0.300000\n",
      "   2  10.198900   2.310000   17.800000   2.300000   0.300000\n",
      "   3  10.198900   2.310000   17.800000   2.300000   0.300000\n",
      "   4  7.710956   2.300547   17.883437   2.088867   0.313711\n",
      "   5  7.710956   2.300547   17.883437   2.088867   0.313711\n",
      "   6  7.710956   2.300547   17.883437   2.088867   0.313711\n",
      "   7  7.710956   2.300547   17.883437   2.088867   0.313711\n",
      "   8  7.710956   2.300547   17.883437   2.088867   0.313711\n",
      "   9  7.710956   2.300547   17.883437   2.088867   0.313711\n",
      "  10  7.710956   2.300547   17.883437   2.088867   0.313711\n",
      "  11  7.710956   2.300547   17.883437   2.088867   0.313711\n",
      "  12  7.710956   2.300547   17.883437   2.088867   0.313711\n",
      "  13  7.573437   2.311439   17.877239   2.133430   0.306403\n",
      "  14  7.445378   2.312507   17.881117   2.076212   0.310466\n",
      "  15  7.445378   2.312507   17.881117   2.076212   0.310466\n",
      "  16  7.445378   2.312507   17.881117   2.076212   0.310466\n",
      "  17  7.445378   2.312507   17.881117   2.076212   0.310466\n",
      "  18  7.445378   2.312507   17.881117   2.076212   0.310466\n",
      "  19  7.445378   2.312507   17.881117   2.076212   0.310466\n",
      "  20  7.415417   2.313344   17.881225   2.102623   0.309096\n",
      "  21  7.395465   2.319305   17.881227   2.065854   0.310660\n",
      "  22  7.395465   2.319305   17.881227   2.065854   0.310660\n",
      "  23  7.395465   2.319305   17.881227   2.065854   0.310660\n",
      "  24  7.395465   2.319305   17.881227   2.065854   0.310660\n",
      "  25  7.345548   2.324640   17.878824   2.115328   0.306847\n",
      "  26  7.345548   2.324640   17.878824   2.115328   0.306847\n",
      "  27  7.345548   2.324640   17.878824   2.115328   0.306847\n",
      "  28  7.292341   2.334745   17.881018   2.080037   0.309029\n",
      "  29  7.237820   2.334588   17.878086   2.138986   0.306783\n",
      "  30  7.237820   2.334588   17.878086   2.138986   0.306783\n",
      "  31  7.213616   2.342133   17.878672   2.145069   0.304355\n",
      "  32  7.187619   2.349208   17.879211   2.121780   0.306616\n",
      "  33  7.057015   2.348044   17.881153   2.144156   0.306571\n",
      "  34  7.057015   2.348044   17.881153   2.144156   0.306571\n",
      "  35  7.057015   2.348044   17.881153   2.144156   0.306571\n",
      "  36  7.043960   2.363227   17.880383   2.167376   0.305582\n",
      "  37  7.043960   2.363227   17.880383   2.167376   0.305582\n",
      "  38  7.043906   2.363956   17.881104   2.202055   0.303417\n",
      "  39  6.900076   2.349345   17.880741   2.186306   0.307835\n",
      "  40  6.900076   2.349345   17.880741   2.186306   0.307835\n",
      "  41  6.900076   2.349345   17.880741   2.186306   0.307835\n",
      "  42  6.900076   2.349345   17.880741   2.186306   0.307835\n",
      "  43  6.874823   2.348050   17.883436   2.206193   0.313548\n",
      "  44  6.741443   2.351257   17.880518   2.275988   0.310343\n",
      "  45  6.724225   2.351676   17.880408   2.218537   0.312147\n",
      "  46  6.724225   2.351676   17.880408   2.218537   0.312147\n",
      "  47  6.724225   2.351676   17.880408   2.218537   0.312147\n",
      "  48  6.724225   2.351676   17.880408   2.218537   0.312147\n",
      "  49  6.700614   2.364461   17.881408   2.277035   0.310992\n",
      "  50  6.670660   2.358530   17.879947   2.296194   0.312000\n",
      "  51  6.670660   2.358530   17.879947   2.296194   0.312000\n",
      "  52  6.554678   2.365232   17.881263   2.244888   0.316829\n",
      "  53  6.554678   2.365232   17.881263   2.244888   0.316829\n",
      "  54  6.552203   2.355383   17.880625   2.291807   0.318466\n",
      "  55  6.521071   2.374045   17.880392   2.308665   0.316369\n",
      "  56  6.491991   2.372266   17.881969   2.289427   0.321434\n",
      "  57  6.473296   2.366530   17.880571   2.241513   0.321344\n",
      "  58  6.460427   2.368880   17.880515   2.320818   0.321977\n",
      "  59  6.459276   2.385478   17.881099   2.288404   0.322096\n",
      "  60  6.429829   2.372532   17.881685   2.261416   0.327057\n",
      "  61  6.421654   2.374444   17.879966   2.266648   0.324803\n",
      "  62  6.401093   2.384137   17.881061   2.327130   0.326622\n",
      "  63  6.401093   2.384137   17.881061   2.327130   0.326622\n",
      "  64  6.385035   2.374786   17.880953   2.264683   0.331301\n",
      "  65  6.385035   2.374786   17.880953   2.264683   0.331301\n",
      "  66  6.385035   2.374786   17.880953   2.264683   0.331301\n",
      "  67  6.384073   2.391940   17.881513   2.310642   0.332417\n",
      "  68  6.370494   2.386149   17.880643   2.241916   0.333496\n",
      "  69  6.365280   2.386662   17.880507   2.282491   0.329890\n",
      "  70  6.343758   2.384783   17.880865   2.280405   0.335498\n",
      "  71  6.343758   2.384783   17.880865   2.280405   0.335498\n",
      "  72  6.343758   2.384783   17.880865   2.280405   0.335498\n",
      "  73  6.343758   2.384783   17.880865   2.280405   0.335498\n",
      "  74  6.343758   2.384783   17.880865   2.280405   0.335498\n",
      "  75  6.343758   2.384783   17.880865   2.280405   0.335498\n",
      "  76  6.343758   2.384783   17.880865   2.280405   0.335498\n",
      "  77  6.343758   2.384783   17.880865   2.280405   0.335498\n",
      "  78  6.343758   2.384783   17.880865   2.280405   0.335498\n",
      "  79  6.341533   2.387750   17.880851   2.278857   0.335075\n",
      "  80  6.341533   2.387750   17.880851   2.278857   0.335075\n",
      "  81  6.341533   2.387750   17.880851   2.278857   0.335075\n",
      "  82  6.341533   2.387750   17.880851   2.278857   0.335075\n",
      "  83  6.341533   2.387750   17.880851   2.278857   0.335075\n",
      "  84  6.341533   2.387750   17.880851   2.278857   0.335075\n",
      "  85  6.339788   2.385690   17.880713   2.273110   0.334945\n",
      "  86  6.339788   2.385690   17.880713   2.273110   0.334945\n",
      "  87  6.339788   2.385690   17.880713   2.273110   0.334945\n",
      "  88  6.339029   2.388448   17.880646   2.273785   0.334817\n",
      "  89  6.339029   2.388448   17.880646   2.273785   0.334817\n",
      "  90  6.338151   2.387817   17.880647   2.268980   0.335246\n",
      "  91  6.337712   2.387043   17.880736   2.274911   0.335226\n",
      "  92  6.337712   2.387043   17.880736   2.274911   0.335226\n",
      "  93  6.337712   2.387043   17.880736   2.274911   0.335226\n",
      "  94  6.337712   2.387043   17.880736   2.274911   0.335226\n",
      "  95  6.337322   2.387995   17.880639   2.272137   0.335219\n",
      "  96  6.336973   2.387160   17.880653   2.272305   0.335171\n",
      "  97  6.336411   2.387176   17.880667   2.271442   0.335372\n",
      "  98  6.336411   2.387176   17.880667   2.271442   0.335372\n",
      "  99  6.336411   2.387176   17.880667   2.271442   0.335372\n",
      " 100  6.336411   2.387176   17.880667   2.271442   0.335372\n",
      " 101  6.336411   2.387176   17.880667   2.271442   0.335372\n",
      " 102  6.336277   2.387038   17.880661   2.272873   0.335237\n",
      " 103  6.336277   2.387038   17.880661   2.272873   0.335237\n",
      " 104  6.336193   2.387791   17.880651   2.272003   0.335265\n",
      " 105  6.336078   2.387229   17.880649   2.272518   0.335282\n",
      " 106  6.336078   2.387229   17.880649   2.272518   0.335282\n",
      " 107  6.335575   2.387219   17.880656   2.272362   0.335300\n",
      " 108  6.335567   2.387337   17.880653   2.272515   0.335277\n",
      " 109  6.335567   2.387337   17.880653   2.272515   0.335277\n",
      " 110  6.335567   2.387337   17.880653   2.272515   0.335277\n",
      " 111  6.335567   2.387337   17.880653   2.272515   0.335277\n",
      " 112  6.335567   2.387337   17.880653   2.272515   0.335277\n",
      " 113  6.335554   2.387292   17.880657   2.272657   0.335303\n",
      " 114  6.335554   2.387292   17.880657   2.272657   0.335303\n",
      " 115  6.335554   2.387292   17.880657   2.272657   0.335303\n",
      " 116  6.335554   2.387292   17.880657   2.272657   0.335303\n",
      " 117  6.335554   2.387292   17.880657   2.272657   0.335303\n",
      " 118  6.335528   2.387324   17.880653   2.272284   0.335295\n",
      " 119  6.335528   2.387324   17.880653   2.272284   0.335295\n",
      " 120  6.335528   2.387324   17.880653   2.272284   0.335295\n",
      " 121  6.335528   2.387324   17.880653   2.272284   0.335295\n",
      " 122  6.335528   2.387324   17.880653   2.272284   0.335295\n",
      " 123  6.335528   2.387324   17.880653   2.272284   0.335295\n",
      " 124  6.335528   2.387324   17.880653   2.272284   0.335295\n",
      " 125  6.335528   2.387324   17.880653   2.272284   0.335295\n",
      " 126  6.335514   2.387339   17.880654   2.272444   0.335299\n",
      " 127  6.335512   2.387327   17.880652   2.272278   0.335295\n",
      " 128  6.335509   2.387348   17.880652   2.272317   0.335294\n",
      " 129  6.335509   2.387348   17.880652   2.272317   0.335294\n",
      " 130  6.335490   2.387384   17.880652   2.272415   0.335299\n",
      " 131  6.335490   2.387384   17.880652   2.272415   0.335299\n",
      " 132  6.335490   2.387384   17.880652   2.272415   0.335299\n",
      " 133  6.335469   2.387406   17.880653   2.272636   0.335300\n",
      " 134  6.335445   2.387406   17.880654   2.272799   0.335307\n",
      " 135  6.335404   2.387462   17.880653   2.272918   0.335306\n",
      " 136  6.335382   2.387568   17.880652   2.273169   0.335315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 137  6.335332   2.387614   17.880655   2.273812   0.335324\n",
      " 138  6.335303   2.387727   17.880654   2.274250   0.335340\n",
      " 139  6.335303   2.387727   17.880654   2.274250   0.335340\n",
      " 140  6.335303   2.387727   17.880654   2.274250   0.335340\n",
      " 141  6.335273   2.387826   17.880654   2.274588   0.335345\n",
      " 142  6.335273   2.387826   17.880654   2.274588   0.335345\n",
      " 143  6.335273   2.387826   17.880654   2.274588   0.335345\n",
      " 144  6.335273   2.387826   17.880654   2.274588   0.335345\n",
      " 145  6.335262   2.387841   17.880655   2.274765   0.335349\n",
      " 146  6.335260   2.387841   17.880654   2.274691   0.335348\n",
      " 147  6.335253   2.387850   17.880654   2.274762   0.335349\n",
      " 148  6.335253   2.387850   17.880654   2.274762   0.335349\n",
      " 149  6.335253   2.387850   17.880654   2.274762   0.335349\n",
      " 150  6.335253   2.387850   17.880654   2.274762   0.335349\n",
      " 151  6.335253   2.387850   17.880654   2.274762   0.335349\n",
      " 152  6.335253   2.387850   17.880654   2.274762   0.335349\n",
      "Duration: 0:13:03.585016\n"
     ]
    }
   ],
   "source": [
    "params_ini = [2.2, 17.8, 2.3, 0.3]\n",
    "Reps       = 5\n",
    "\n",
    "Nfeval = 1\n",
    "\n",
    "def callbackF(xk):\n",
    "    global Nfeval\n",
    "    print ('{0:4d} {1: 3.6f}  {2: 3.6f}  {3: 3.6f}  {4: 3.6f}  {5: 3.6f}'\\\n",
    "           .format(Nfeval, get_MomentCondition(xk, Reps), xk[0], xk[1], xk[2], xk[3]))\n",
    "    Nfeval += 1\n",
    "\n",
    "print  ('{0:4s}     {1:9s}   {2:9s}  {3:9s}  {4:9s}  {5:9s}'\\\n",
    "        .format('Iter', 'f(X)',  ' sigma', ' theta',  'k', 'mu_c'))\n",
    "\n",
    "start_time = datetime.now()\n",
    "betas = minimize(get_MomentCondition, x0=params_ini, \n",
    "                 args=(Reps), \n",
    "                 method='Nelder-Mead', \n",
    "                 tol=0.0001,\n",
    "                 callback = callbackF, \n",
    "                 options={'maxiter':1000})\n",
    "\n",
    "final_sigma1e52, final_theta1e52, final_k1e52, final_muc1e52 = betas['x']\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a8f6025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24715408 0.0245752  1.39566964 0.83316151 1.16178603 0.56783955\n",
      " 0.21245643]\n",
      "[0.2228 0.0647 1.3992 0.83   1.16   0.4609 0.2082]\n"
     ]
    }
   ],
   "source": [
    "# Test our code.\n",
    "simulated_mmtRst = getSimulMMt(final_sigma1e52, final_theta1e52, final_k1e52, final_muc1e52, 10)\n",
    "print(simulated_mmtRst)\n",
    "print(data_moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28db256a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.34616035, 20.05298081,  2.15190703,  0.32033915],\n",
       "       [ 2.38784976, 17.88065423,  2.27476246,  0.33534905]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibration_rst1 = np.array([final_sigma1e51, final_theta1e51, final_k1e51, final_muc1e51])\n",
    "calibration_rst2 = np.array([final_sigma1e52, final_theta1e52, final_k1e52, final_muc1e52])\n",
    "calibration_rst  = np.stack((calibration_rst1, calibration_rst2))\n",
    "calibration_rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7566b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sigma</th>\n",
       "      <th>theta</th>\n",
       "      <th>k</th>\n",
       "      <th>mu_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.34616</td>\n",
       "      <td>20.052981</td>\n",
       "      <td>2.151907</td>\n",
       "      <td>0.320339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.38785</td>\n",
       "      <td>17.880654</td>\n",
       "      <td>2.274762</td>\n",
       "      <td>0.335349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sigma      theta         k      mu_c\n",
       "0  2.34616  20.052981  2.151907  0.320339\n",
       "1  2.38785  17.880654  2.274762  0.335349"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibration_rst = pd.DataFrame(calibration_rst, columns=['sigma', 'theta', 'k', 'mu_c'])\n",
    "calibration_rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97aa0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_rst.to_csv(path +'calibration_rstJune122023.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e61d3568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11730802, 1.00264904, 0.10759535, 0.01601696])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compute the Jacobian matrix (rows: moments, columns: parameters)\n",
    "\n",
    "theta = np.array([final_sigma1e51, final_theta1e51, final_k1e51, final_muc1e51])\n",
    "\n",
    "# Note that we have 7 moments and 4 parameters.\n",
    "Nmom  = 7\n",
    "nparm = 4\n",
    "G     = np.zeros((Nmom,nparm))\n",
    "\n",
    "# around 5% pertubation(theta*0.05)\n",
    "h = theta*0.05\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d05a6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "510dff27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 finished.\n",
      "2 finished.\n",
      "3 finished.\n",
      "4 finished.\n"
     ]
    }
   ],
   "source": [
    "for i in range(nparm):\n",
    "    thetah    = copy.deepcopy(theta)\n",
    "    thetah[i] = thetah[i]+h[i]\n",
    "    thetal    = copy.deepcopy(theta)\n",
    "    thetal[i] = thetal[i]-h[i]\n",
    "    momentsh  = getSimulMMt(thetah[0], thetah[1], thetah[2], thetah[3], 10)\n",
    "    momentsl  = getSimulMMt(thetal[0], thetal[1], thetal[2], thetal[3], 10)\n",
    "    G[:,i]    = np.array((momentsh-momentsl)/(2*h[i]))\n",
    "    print('{0} finished.'.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e38ed0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate lambda: Lambda=(G'*weight*G)\\(G'*weight);\n",
    "temp1  = np.matmul(np.matmul(G.T, w), G)\n",
    "temp2  = np.matmul(G.T, w)\n",
    "Lambda = np.matmul(np.linalg.inv(temp1), temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90ef0671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08668218, 0.21146636, 0.32438855, 0.04739355])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the ste: ste=[(.^0.5)'];\n",
    "temp1 = np.matmul(Lambda, var_matrix)\n",
    "temp2 = (1+1/10)*np.matmul(temp1, Lambda.T)\n",
    "ste = np.diag(temp2)**(0.5)\n",
    "ste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "397ed3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27.06623755, 94.82823221,  6.63373302,  6.75912946])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conduct inference.\n",
    "theta/ste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c1fccbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.34616035, 20.05298081,  2.15190703,  0.32033915])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final parameters we have.\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50196d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
